{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: benchmarking_script (10 points)\n",
    "\n",
    "End-to-end benchmarking of forward and backward passes for `BasicsTransformerLM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import timeit\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from a1_basics.model import BasicsTransformerLM\n",
    "from student.basicprofiling import benchmark, MODEL_SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b): Time forward and backward passes for all model sizes\n",
    "\n",
    "Use 5 warmup steps, 10 measurement steps. Report average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_lengths = [128, 256, 512, 1024]\n",
    "results = []\n",
    "\n",
    "for size_name, params in MODEL_SIZES.items():\n",
    "    for ctx_len in context_lengths:\n",
    "        for mode in [\"forward\", \"forward+backward\"]:\n",
    "            backward = mode == \"forward+backward\"\n",
    "            print(f\"--- {size_name} | ctx={ctx_len} | {mode} ---\")\n",
    "            try:\n",
    "                times = benchmark(\n",
    "                    d_model=params[\"d_model\"],\n",
    "                    d_ff=params[\"d_ff\"],\n",
    "                    num_layers=params[\"num_layers\"],\n",
    "                    num_heads=params[\"num_heads\"],\n",
    "                    context_length=ctx_len,\n",
    "                    warmup_steps=5,\n",
    "                    num_steps=10,\n",
    "                    backward=backward,\n",
    "                    device=DEVICE,\n",
    "                )\n",
    "                avg = sum(times) / len(times) * 1000\n",
    "                std = math.sqrt(sum((t - avg / 1000) ** 2 for t in times) / len(times)) * 1000\n",
    "                results.append({\n",
    "                    \"model\": size_name,\n",
    "                    \"ctx_len\": ctx_len,\n",
    "                    \"mode\": mode,\n",
    "                    \"avg_ms\": round(avg, 2),\n",
    "                    \"std_ms\": round(std, 2),\n",
    "                })\n",
    "            except RuntimeError as e:\n",
    "                print(f\"  OOM or error: {e}\")\n",
    "                results.append({\n",
    "                    \"model\": size_name,\n",
    "                    \"ctx_len\": ctx_len,\n",
    "                    \"mode\": mode,\n",
    "                    \"avg_ms\": \"OOM\",\n",
    "                    \"std_ms\": \"OOM\",\n",
    "                })\n",
    "            # Free GPU memory between runs\n",
    "            if DEVICE == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_b = pd.DataFrame(results)\n\n# Pivot into a readable table: rows = (model, ctx_len), columns = mode\npivot_avg = df_b.pivot_table(index=[\"model\", \"ctx_len\"], columns=\"mode\", values=\"avg_ms\", aggfunc=\"first\")\npivot_std = df_b.pivot_table(index=[\"model\", \"ctx_len\"], columns=\"mode\", values=\"std_ms\", aggfunc=\"first\")\n\n# Combine avg ± std into a single string per cell\ndef fmt_cell(avg, std):\n    if avg == \"OOM\" or std == \"OOM\":\n        return \"OOM\"\n    return f\"{avg:.2f} ± {std:.2f}\"\n\ncombined = pd.DataFrame(index=pivot_avg.index)\nfor col in pivot_avg.columns:\n    combined[col] = [\n        fmt_cell(a, s) for a, s in zip(pivot_avg[col], pivot_std[col])\n    ]\n\ncombined.columns.name = None\ncombined = combined.rename(columns={\"forward\": \"Forward (ms)\", \"forward+backward\": \"Fwd+Bwd (ms)\"})\n\nprint(\"=== Markdown ===\")\nprint(combined.to_markdown())\nprint()\nprint(\"=== LaTeX ===\")\nprint(combined.to_latex())\n\ncombined"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) response\n",
    "\n",
    "_Fill in after running:_ A 1-2 sentence response with your timings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c): Effect of warm-up steps\n",
    "\n",
    "Repeat the analysis with 0, 1, 2, and 5 warm-up steps to see the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 'small' model at ctx_len=128 as a representative example\n",
    "warmup_values = [0, 1, 2, 5]\n",
    "warmup_results = []\n",
    "\n",
    "params = MODEL_SIZES[\"small\"]\n",
    "\n",
    "for w in warmup_values:\n",
    "    for mode in [\"forward\", \"forward+backward\"]:\n",
    "        backward = mode == \"forward+backward\"\n",
    "        print(f\"--- warmup={w} | {mode} ---\")\n",
    "        times = benchmark(\n",
    "            d_model=params[\"d_model\"],\n",
    "            d_ff=params[\"d_ff\"],\n",
    "            num_layers=params[\"num_layers\"],\n",
    "            num_heads=params[\"num_heads\"],\n",
    "            context_length=128,\n",
    "            warmup_steps=w,\n",
    "            num_steps=10,\n",
    "            backward=backward,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        avg = sum(times) / len(times) * 1000\n",
    "        std = math.sqrt(sum((t - avg / 1000) ** 2 for t in times) / len(times)) * 1000\n",
    "        warmup_results.append({\n",
    "            \"warmup_steps\": w,\n",
    "            \"mode\": mode,\n",
    "            \"avg_ms\": round(avg, 2),\n",
    "            \"std_ms\": round(std, 2),\n",
    "            \"first_step_ms\": round(times[0] * 1000, 2),\n",
    "        })\n",
    "        if DEVICE == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_c = pd.DataFrame(warmup_results)\n\n# Pivot: rows = warmup_steps, columns = mode, values = \"avg ± std\"\npivot_avg = df_c.pivot_table(index=\"warmup_steps\", columns=\"mode\", values=\"avg_ms\", aggfunc=\"first\")\npivot_std = df_c.pivot_table(index=\"warmup_steps\", columns=\"mode\", values=\"std_ms\", aggfunc=\"first\")\npivot_first = df_c.pivot_table(index=\"warmup_steps\", columns=\"mode\", values=\"first_step_ms\", aggfunc=\"first\")\n\ntable_c = pd.DataFrame(index=pivot_avg.index)\nfor col in pivot_avg.columns:\n    table_c[f\"{col} avg±std (ms)\"] = [\n        f\"{a:.2f} ± {s:.2f}\" for a, s in zip(pivot_avg[col], pivot_std[col])\n    ]\n    table_c[f\"{col} 1st step (ms)\"] = [f\"{v:.2f}\" for v in pivot_first[col]]\n\ntable_c.columns.name = None\ntable_c.index.name = \"warmup\"\n\nprint(\"=== Markdown ===\")\nprint(table_c.to_markdown())\nprint()\nprint(\"=== LaTeX ===\")\nprint(table_c.to_latex())\n\ntable_c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c) response\n",
    "\n",
    "_Fill in after running:_ A 2-3 sentence response."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}